# The Comparative Hybrid Approach to Investigate Cognition across Substrates

This work is accepted as a full paper to the 2021 Conference on Artificial Life.

## Overview

This work uses a new approach, the _comparative hybrid approach_, to investigate what components of computational structures allow for the performance of certain cognitive tasks.

## Abstract

Understanding the structure and evolution of cognition is a topic of broad scientific interest across disciplines. 
Computational substrates are ideal for conducting investigations into this topic because they can be incorporated in rapidly evolving Artificial Life systems and are easy to manipulate at both small and large scales.
However, it can still be challenging to identify how such manipulations correlate with broad patterns in evolved behavior, especially if we are trying to disentangle how multiple features interact.
Here we systematically analyze components from two evolvable digital neural substrates (recurrent neural networks and Markov brains) to develop a proof-of-concept for a comparative hybrid approach. 
We first identified the core logic and memory storage architectures in each substrate, then altered these structures to create hybrids that recombine properties of each original substrate. 
We then tested these hybrids across a suite of distinct environments in which the canonical structures differed in evolved performance. 
While we observed trends across different options for core logic, sparsity of a network, and whether memory values were limited to discrete states, we identified the last of these, discreteness of memory, as an especially important determinant of performance across our tested conditions. 
However, the specific effect of discretization varied by environment and whether the associated task required integration of information across different time points or spatial locations.
Our results demonstrate that this comparative hybrid approach can isolate structural components that enable cognition and facilitate task performance across multiple computational structures.

## Reproducibility

Coming soon!
